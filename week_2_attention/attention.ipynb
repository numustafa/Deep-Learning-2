{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/numustafa/Deep-Learning-2/blob/main/week_2_attention/attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJ3mjOB5xfx"
      },
      "source": [
        "# DL2 - Sheet 02: Attention (50 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JbRSfAt6qeH",
        "outputId": "7f656eed-a323-4a5b-d578-ea2f296b61a0",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the transformers library if necessary\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qylqS4zZg4a7"
      },
      "source": [
        "\n",
        "# Intro: Transformers for Sequence Classification\n",
        "\n",
        "In this weeks notebook, we will implement our own Transformer model from scratch. Typical Transformers can be broken down into the following components:\n",
        "Remark: Here, we will focus on the encoding of sentences for the purpose of sentiment classification, the decoder used in sequence2sequences Transformers has a very similar structure.\n",
        "\n",
        "\n",
        "\n",
        "1.   Embedding: An embedding layer that transforms word tokens into vector representations.\n",
        "2.  Encoder: The encoder block consists of several multi-headed attention blocks\n",
        "\n",
        "    2.1.   Attention block 1\n",
        "\n",
        "    2.2.   Attention block 2\n",
        "\n",
        "    ...\n",
        "\n",
        "    2.L.   Attention block L\n",
        "\n",
        "3. Pooling: The final output of the encoder computes one vector representation for each token. To further summarize/pool this information for classification, the [CLS] token at sequence position 0 is typically selected.\n",
        "\n",
        "4. Classification: A standard small MLP is used for classification and outputs probabilites for the most likely predicted class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uKBFg887DiO"
      },
      "source": [
        "## Preparation: From sentences to tokens\n",
        "\n",
        "First, we will use hugginface's tokenizer to go from words to indices in the vocabulary. In the following, we will focus on the distilBERT model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "3a5eaebc95824bfa884a2264b40ba884",
            "9cf9305c06ac4aed8fa6d7977030f2db",
            "8e9704fb11674a81bb86da5359121ce5",
            "bf318435abae4b04a6f78d16d449af18",
            "5beedc59a8104137b69bccd19f6c9fb8",
            "2350b0bced494960a57e8485ad186925",
            "ff1c3d5657774f539db80710cf81b5e0",
            "5e7dfe57f1924f85b6c0412d8e4e9ec2",
            "593f36d2f08b460097099f7002c8ba7c",
            "acc220fa59494fbf857f89ac4495cc4d",
            "b383294bafaa4b4c8ef736085f0b0913",
            "c04315acb15e46c6b45feb164f9d5b67",
            "67eb763e98e94784bcd16c289c35ace2",
            "88fc8a118bc34bfc9d1c194d4848d95b",
            "7d6d0b04082f4de8a7f1baa9a9af4944",
            "54a789e980ee4ded8c458a8c62b93c60",
            "eb34ce3595814247936a3ab9e7e33b9f",
            "7244857021814e82abbf74c32fc856a4",
            "237989ead34248af8afd81abfbaaef46",
            "23be9c11e0d44e9a846a4eb21ca0ff38",
            "20c4fd98f31d4113b0515d78c8e26619",
            "5c3abeb87e2a441988fd43ca1822a27a",
            "eabc04b270bf4f74a6b43eaa5ed87e38",
            "ce259f960f834820a14e38eff73e1be5",
            "be52db8d577e454abd25748e5b5d3b28",
            "29b5ba8bde024e239fff12e8180a5afe",
            "9a5eef0ad8ec4f08b0b2bf8b19254233",
            "68c1b8d0fd0146029dcfab8cc824e664",
            "492b3e337c774658b9c57e8a54300c68",
            "70a8607cd5994810b05da6506db7aacf",
            "dd45818ea4da43c1b7334f33891238b5",
            "2bd230bbe1404e72abe9a8cfbc03efa6",
            "a85cc2be909345f89c37aab95bbfb746",
            "939a5c37325d4d70af059f79d3160ab5",
            "c22065248ad64399a980cc6ea01c1a22",
            "54326839415e49c4a24a0823142460c2",
            "e70f641f53c640f1a54fb6687173ca8b",
            "e9a0052949e64e628a148fe315612b22",
            "506ca83fd0a14ba08623cd4669b9982e",
            "ae89b55f3c0e438dbd33d21a64be81dd",
            "c842ed6afb4843cfbf69adfb13b947b7",
            "4976aa451e7942998c4e032b1a3f3d64",
            "191ad8868d2c414287f53d095537cbda",
            "baccfc87d97846d5b58c3b40cbbc55c4"
          ]
        },
        "id": "dog9jZDt7SuB",
        "outputId": "2daf58c5-251d-4173-9169-29dc65940638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a5eaebc95824bfa884a2264b40ba884"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c04315acb15e46c6b45feb164f9d5b67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eabc04b270bf4f74a6b43eaa5ed87e38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "939a5c37325d4d70af059f79d3160ab5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 2023, 2001, 2028, 1997, 1996, 2190, 5691, 1045, 2031, 2412, 2464,\n",
            "         1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "sentence = \"This was one of the best movies I have ever seen.\"\n",
        "inputs = tokenizer(sentence, return_tensors = 'pt')\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lzoe-QSslj7",
        "outputId": "0b83b40c-9b0c-4933-94a3-fcf10b61b815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-05 10:06:06--  https://tubcloud.tu-berlin.de/s/GfEoq4r8Sgb2727/download/distilbert.pt\n",
            "Resolving tubcloud.tu-berlin.de (tubcloud.tu-berlin.de)... 141.23.34.165\n",
            "Connecting to tubcloud.tu-berlin.de (tubcloud.tu-berlin.de)|141.23.34.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 267854575 (255M) [application/octet-stream]\n",
            "Saving to: ‘distilbert.pt’\n",
            "\n",
            "distilbert.pt       100%[===================>] 255.45M  3.13MB/s    in 86s     \n",
            "\n",
            "2024-05-05 10:07:34 (2.97 MB/s) - ‘distilbert.pt’ saved [267854575/267854575]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Now we download pretrained weights for the model.\n",
        "! wget https://tubcloud.tu-berlin.de/s/GfEoq4r8Sgb2727/download/distilbert.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "t7-hhXPY7FY2"
      },
      "outputs": [],
      "source": [
        "# This config contains the model parameters, it will be important to understand what representations\n",
        "# have which dimensionality\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "import torch\n",
        "\n",
        "class Config(object):\n",
        "    def __init__(self):\n",
        "        self.n_heads = 12\n",
        "        self.n_layers = 6\n",
        "        self.pad_token_id = 0\n",
        "        self.dim = 768\n",
        "        self.hidden_dim = 3072\n",
        "        self.max_position_embeddings = 512\n",
        "        self.vocab_size = 30522\n",
        "        self.eps = 1e-12\n",
        "\n",
        "        self.attention_head_size = int(self.dim / self.n_heads)\n",
        "        self.all_head_size = self.n_heads * self.attention_head_size\n",
        "\n",
        "        self.n_classes = 2\n",
        "        self.device = 'cpu'\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0TwrwBqT0P"
      },
      "source": [
        "# 1. Embedding Layer (5p)\n",
        "Next, we will have to implement the Embedding layer.\n",
        "\n",
        "\n",
        "1.   forward: compute the output embeddings from the input_embeds and position_embeds. (Think about how they are merged.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YmDPyUH27PUW"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0) # set seed for reproducible random initialization of weights\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.dim, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.dim)\n",
        "        self.LayerNorm = nn.LayerNorm(config.dim, eps=config.eps)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            input_ids (torch.Tensor):\n",
        "                torch.tensor(bs, max_seq_length) The token ids to embed.\n",
        "        Returns: torch.tensor(bs, max_seq_length, dim) The embedded tokens (plus position embeddings)\n",
        "        \"\"\"\n",
        "\n",
        "        # Embedding the input ids\n",
        "        input_embeds = self.word_embeddings(input_ids)  # (bs, max_seq_length, dim)\n",
        "        seq_length = input_embeds.size(1)\n",
        "\n",
        "        # Creating and embedding the position ids\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # (max_seq_length)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (bs, max_seq_length)\n",
        "        position_embeddings = self.position_embeddings(position_ids)  # (bs, max_seq_length, dim)\n",
        "\n",
        "        # Compute the output embeddings\n",
        "\n",
        "        # 1. START YOUR CODE HERE #\n",
        "        # Combine the input and position embeddings\n",
        "        embeddings = input_embeds + position_embeddings  # add word and position embeddings\n",
        "        # 1. END YOUR CODE HERE #\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)  # (bs, max_seq_length, dim)\n",
        "        return embeddings\n",
        "\n",
        "embedding_layer = Embeddings(config)\n",
        "# Test if your embedding layer computes an output\n",
        "embeddings = embedding_layer(inputs['input_ids'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9Hr4HyuyYX"
      },
      "source": [
        "# 2. Attention Block (20 points)\n",
        "The next step is writing the attention block. It mainly consits of the self-attention function (that you have analyzed in the first part of the exercise sheet), a layer normalization followed by an additional projection layer.\n",
        "\n",
        "Please add the missing code:\n",
        "\n",
        "\n",
        "1.   \\_\\_init\\_\\_: Add the Linear projections for the query, key and value functions. Make sure your set the correct dimensions.\n",
        "2.   forward: Write the main self-attention function. Follow the three main steps as indicated in the comments below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aQU3ZBanto79",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # self-attention components\n",
        "\n",
        "        # 1. START YOUR CODE HERE #\n",
        "\n",
        "        # Self-attention components\n",
        "        self.q_lin = nn.Linear(in_features=config.dim, out_features=config.dim, bias=True)\n",
        "        self.k_lin = nn.Linear(in_features=config.dim, out_features=config.dim, bias=True)\n",
        "        self.v_lin = nn.Linear(in_features=config.dim, out_features=config.dim, bias=True)\n",
        "\n",
        "        # 1. END YOUR CODE HERE #\n",
        "\n",
        "        self.out_lin = nn.Linear(in_features=config.dim, out_features=config.dim, bias=True)\n",
        "        self.sa_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=config.eps)\n",
        "\n",
        "        # feed-forward network\n",
        "        self.lin1 = nn.Linear(in_features=config.dim, out_features=3072, bias=True)\n",
        "        self.lin2 = nn.Linear(in_features=3072, out_features=config.dim, bias=True)\n",
        "        self.output_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=config.eps)\n",
        "\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "\n",
        "        def shape(x):\n",
        "            \"\"\" separate heads \"\"\"\n",
        "            return x.view(1, -1, 12, 64).transpose(1, 2)\n",
        "\n",
        "        def unshape(x):\n",
        "            \"\"\" group heads \"\"\"\n",
        "            return x.transpose(1, 2).contiguous().view(1, -1, 12 * 64)\n",
        "\n",
        "        bs=hidden_states.shape[0]\n",
        "        n_nodes= hidden_states.shape[1]\n",
        "\n",
        "        query=key=value=hidden_states\n",
        "        q = self.q_lin(query)\n",
        "        k = self.k_lin(key)\n",
        "        v = self.v_lin(value)\n",
        "\n",
        "        # Separating the heads\n",
        "        q = shape(q)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        k = shape(k)  # (bs, n_heads, k_length, dim_per_head)\n",
        "        v = shape(v)  # (bs, n_heads, k_length, dim_per_head)\n",
        "\n",
        "        # Normalizing the query-tensor\n",
        "        q = q / math.sqrt(q.shape[-1])\n",
        "\n",
        "\n",
        "        # 2. START YOUR CODE HERE #\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.matmul(q, k.transpose(-2, -1))\n",
        "\n",
        "\n",
        "        # Transform the scores into probability distribution via softmax\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # Compute the weighted representation of the value-tensor (aka context)\n",
        "        context = torch.matmul(attention_probs, v)\n",
        "\n",
        "        # 2. END YOUR CODE HERE #\n",
        "\n",
        "        # Merging the heads again\n",
        "        context = unshape(context)  # (bs, q_length, dim)\n",
        "\n",
        "        # Additional projection of the context to get the output of the self-attention block\n",
        "        sa_output = self.out_lin(context)\n",
        "        sa_output = self.sa_layer_norm(sa_output + hidden_states)\n",
        "\n",
        "        # Feed-forward network to compute the attention block output\n",
        "        x = self.lin1(sa_output)\n",
        "        x = nn.functional.gelu(x)\n",
        "        ffn_output = self.lin2(x)\n",
        "        ffn_output = self.output_layer_norm(ffn_output + sa_output)\n",
        "        weights = attention_probs\n",
        "\n",
        "        return  ffn_output, weights\n",
        "\n",
        "block = AttentionBlock(config)\n",
        "# Test if your attention block computes an output\n",
        "block_output = block(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soXrKoNsV2gv",
        "outputId": "caa98761-9f2b-47a6-e496-ca9de9c70b88"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.7114, -0.0722, -0.5230,  ..., -0.1903, -0.7819, -0.5930],\n",
              "          [ 0.2216, -0.9576,  0.9970,  ..., -0.0926, -1.1536,  0.8901],\n",
              "          [ 0.4497, -0.6879,  1.1513,  ...,  0.0209, -0.9052,  1.1951],\n",
              "          ...,\n",
              "          [-0.1305, -0.3480,  0.5797,  ...,  0.3764, -0.8779,  0.5787],\n",
              "          [ 0.6187,  0.2542,  0.1652,  ...,  1.0826, -1.0824,  0.9224],\n",
              "          [-0.1873,  0.0490,  0.7358,  ..., -1.2114, -0.6134, -0.7558]]],\n",
              "        grad_fn=<NativeLayerNormBackward0>),\n",
              " tensor([[[[0.0434, 0.0909, 0.0583,  ..., 0.1567, 0.0598, 0.0668],\n",
              "           [0.0969, 0.0588, 0.0794,  ..., 0.0579, 0.0654, 0.0741],\n",
              "           [0.0529, 0.0764, 0.0608,  ..., 0.0522, 0.0904, 0.0868],\n",
              "           ...,\n",
              "           [0.0657, 0.0971, 0.1063,  ..., 0.0665, 0.0505, 0.0848],\n",
              "           [0.0883, 0.0417, 0.1146,  ..., 0.1033, 0.0529, 0.0934],\n",
              "           [0.1194, 0.0599, 0.0607,  ..., 0.0505, 0.0614, 0.0591]],\n",
              " \n",
              "          [[0.0197, 0.0776, 0.0725,  ..., 0.0774, 0.0452, 0.1007],\n",
              "           [0.0580, 0.0531, 0.1805,  ..., 0.0595, 0.0481, 0.0488],\n",
              "           [0.0740, 0.0582, 0.0836,  ..., 0.0834, 0.0513, 0.0613],\n",
              "           ...,\n",
              "           [0.0609, 0.0808, 0.0940,  ..., 0.0750, 0.0579, 0.0563],\n",
              "           [0.0940, 0.0579, 0.0625,  ..., 0.0605, 0.0566, 0.0800],\n",
              "           [0.0347, 0.1090, 0.0651,  ..., 0.0415, 0.0822, 0.0602]],\n",
              " \n",
              "          [[0.0713, 0.0696, 0.0610,  ..., 0.0518, 0.0681, 0.0424],\n",
              "           [0.0995, 0.0449, 0.0531,  ..., 0.0194, 0.0455, 0.0827],\n",
              "           [0.0792, 0.0897, 0.0594,  ..., 0.0341, 0.0447, 0.1238],\n",
              "           ...,\n",
              "           [0.0578, 0.1115, 0.0490,  ..., 0.0912, 0.0793, 0.0916],\n",
              "           [0.1088, 0.0735, 0.0675,  ..., 0.0452, 0.0388, 0.0921],\n",
              "           [0.0817, 0.0562, 0.0701,  ..., 0.0554, 0.0796, 0.0604]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[0.0477, 0.0677, 0.0459,  ..., 0.0571, 0.0909, 0.0790],\n",
              "           [0.0645, 0.0570, 0.0538,  ..., 0.1012, 0.0618, 0.0555],\n",
              "           [0.0779, 0.0998, 0.0554,  ..., 0.0543, 0.0790, 0.0684],\n",
              "           ...,\n",
              "           [0.0735, 0.0531, 0.0597,  ..., 0.0728, 0.0636, 0.0572],\n",
              "           [0.0682, 0.0776, 0.0640,  ..., 0.0703, 0.0635, 0.0671],\n",
              "           [0.0599, 0.0946, 0.0948,  ..., 0.1572, 0.0878, 0.0454]],\n",
              " \n",
              "          [[0.0749, 0.0834, 0.0690,  ..., 0.0588, 0.0469, 0.0702],\n",
              "           [0.0808, 0.0887, 0.0401,  ..., 0.1106, 0.0904, 0.0474],\n",
              "           [0.0630, 0.0525, 0.0656,  ..., 0.0826, 0.0535, 0.0649],\n",
              "           ...,\n",
              "           [0.0954, 0.0685, 0.0830,  ..., 0.0772, 0.0390, 0.0527],\n",
              "           [0.0751, 0.1311, 0.0592,  ..., 0.0547, 0.0957, 0.0692],\n",
              "           [0.0841, 0.0517, 0.0462,  ..., 0.0726, 0.0990, 0.0743]],\n",
              " \n",
              "          [[0.0448, 0.0504, 0.0980,  ..., 0.0628, 0.0405, 0.0326],\n",
              "           [0.0600, 0.0585, 0.0775,  ..., 0.0950, 0.0999, 0.0700],\n",
              "           [0.0575, 0.1256, 0.0897,  ..., 0.0512, 0.0349, 0.1047],\n",
              "           ...,\n",
              "           [0.0649, 0.0609, 0.0928,  ..., 0.0484, 0.0931, 0.0536],\n",
              "           [0.0668, 0.0944, 0.0297,  ..., 0.0597, 0.0402, 0.0861],\n",
              "           [0.0919, 0.0231, 0.0281,  ..., 0.0641, 0.0864, 0.0764]]]],\n",
              "        grad_fn=<SoftmaxBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCPG7i54bme"
      },
      "source": [
        "# 3. Building the model (15 points)\n",
        "\n",
        "Now, we can finally put it all together. For this, please, write the following missing code:\n",
        "\n",
        "\n",
        "1.   \\_\\_init\\_\\_: Add the attention layers (the encoder) to the model.\n",
        "2.   forward: Add the missing code for sequentially looping through the attention layers.\n",
        "3. forward: Add the classifier, which consists of [1. pre_classifier, 2. ReLU activation, 3. classifier] and eventually returns the logit scores.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gRF7FjRc4Am_"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class DistillBertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.n_layers=config.n_layers\n",
        "\n",
        "        # embedding\n",
        "        self.embeddings = Embeddings(config)\n",
        "\n",
        "        # encoder\n",
        "        # 1. START YOUR CODE HERE #\n",
        "\n",
        "        # Assuming each layer in the encoder is an instance of the AttentionBlock class\n",
        "        self.attention_layers = nn.ModuleList([AttentionBlock(config) for _ in range(config.n_layers)])\n",
        "\n",
        "        # 1. END YOUR CODE HERE #\n",
        "\n",
        "        # classification\n",
        "        self.pre_classifier =  nn.Linear(in_features=config.dim, out_features=config.dim, bias=True)\n",
        "        self.classifier =  nn.Linear(in_features=config.dim, out_features=config.n_classes, bias=True)\n",
        "\n",
        "        self.attention_probs = {i: [] for i in range(config.n_layers)}\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            input_ids (torch.Tensor): torch.tensor(bs, max_seq_length) The token ids to embed.\n",
        "        Returns: torch.tensor(bs, n_classes) The computed logit scores for each class.\n",
        "        \"\"\"\n",
        "\n",
        "        # Computing the embeddings\n",
        "        hidden_states =  self.embeddings(input_ids=input_ids).to(self.config.device)\n",
        "\n",
        "        # Iteratively going through the attention layers\n",
        "        encoder_input = hidden_states\n",
        "        # 2. START YOUR CODE HERE #\n",
        "        for layer in self.attention_layers:\n",
        "          encoder_input = layer(encoder_input)\n",
        "        # 2. END YOUR CODE HERE #\n",
        "\n",
        "        # Pooling by selection the [CLS] token\n",
        "        pooled_output = output[:, 0]  # (bs, dim)\n",
        "\n",
        "        # Classification\n",
        "        # 3. START YOUR CODE HERE #\n",
        "        x = self.pre_classifier(pooled_output)\n",
        "        x = F.relu(x)  # Apply ReLU activation\n",
        "        logits = self.classifier(x)\n",
        "        # 3. END YOUR CODE HERE #\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = DistillBertAttention(config)\n",
        "state_dict = torch.load('distilbert.pt')\n",
        "_ = model.load_state_dict(state_dict)\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "nShWppdO5gO8",
        "outputId": "c95cb283-b140-4a01-cab6-c03253d43613"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9fd03336da87>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict your output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-206319c147d5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# 2. START YOUR CODE HERE #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m           \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# 2. END YOUR CODE HERE #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-7b7e96f46750>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mn_nodes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "# Predict your output\n",
        "logits = model(inputs['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265U1cxLzy_s"
      },
      "source": [
        "# 4. Visualize the attention weights (10 points)\n",
        "\n",
        "Let's now look at what tokens the model selects in its self-attention blocks.\n",
        "\n",
        "1.   Use the tokenizer to map the 'input_ids' back to 'tokens'.\n",
        "2.   Extract attention probabilities for every layer by averaging over the attention heads in each layer. You should get a matrix of size [n_layers x seq_length x seq_length]\n",
        "3. For each layer plot the resulting attention matrix. Hint: Use cmap='Reds' and vmin=0, vmax=1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBWOrB0e1qeS",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# YOUR CODE HERE #\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a5eaebc95824bfa884a2264b40ba884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cf9305c06ac4aed8fa6d7977030f2db",
              "IPY_MODEL_8e9704fb11674a81bb86da5359121ce5",
              "IPY_MODEL_bf318435abae4b04a6f78d16d449af18"
            ],
            "layout": "IPY_MODEL_5beedc59a8104137b69bccd19f6c9fb8"
          }
        },
        "9cf9305c06ac4aed8fa6d7977030f2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2350b0bced494960a57e8485ad186925",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1c3d5657774f539db80710cf81b5e0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8e9704fb11674a81bb86da5359121ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7dfe57f1924f85b6c0412d8e4e9ec2",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_593f36d2f08b460097099f7002c8ba7c",
            "value": 28
          }
        },
        "bf318435abae4b04a6f78d16d449af18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc220fa59494fbf857f89ac4495cc4d",
            "placeholder": "​",
            "style": "IPY_MODEL_b383294bafaa4b4c8ef736085f0b0913",
            "value": " 28.0/28.0 [00:00&lt;00:00, 771B/s]"
          }
        },
        "5beedc59a8104137b69bccd19f6c9fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2350b0bced494960a57e8485ad186925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1c3d5657774f539db80710cf81b5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e7dfe57f1924f85b6c0412d8e4e9ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593f36d2f08b460097099f7002c8ba7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acc220fa59494fbf857f89ac4495cc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b383294bafaa4b4c8ef736085f0b0913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c04315acb15e46c6b45feb164f9d5b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67eb763e98e94784bcd16c289c35ace2",
              "IPY_MODEL_88fc8a118bc34bfc9d1c194d4848d95b",
              "IPY_MODEL_7d6d0b04082f4de8a7f1baa9a9af4944"
            ],
            "layout": "IPY_MODEL_54a789e980ee4ded8c458a8c62b93c60"
          }
        },
        "67eb763e98e94784bcd16c289c35ace2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb34ce3595814247936a3ab9e7e33b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_7244857021814e82abbf74c32fc856a4",
            "value": "config.json: 100%"
          }
        },
        "88fc8a118bc34bfc9d1c194d4848d95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237989ead34248af8afd81abfbaaef46",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23be9c11e0d44e9a846a4eb21ca0ff38",
            "value": 483
          }
        },
        "7d6d0b04082f4de8a7f1baa9a9af4944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c4fd98f31d4113b0515d78c8e26619",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3abeb87e2a441988fd43ca1822a27a",
            "value": " 483/483 [00:00&lt;00:00, 15.1kB/s]"
          }
        },
        "54a789e980ee4ded8c458a8c62b93c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb34ce3595814247936a3ab9e7e33b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7244857021814e82abbf74c32fc856a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "237989ead34248af8afd81abfbaaef46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23be9c11e0d44e9a846a4eb21ca0ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20c4fd98f31d4113b0515d78c8e26619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3abeb87e2a441988fd43ca1822a27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eabc04b270bf4f74a6b43eaa5ed87e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce259f960f834820a14e38eff73e1be5",
              "IPY_MODEL_be52db8d577e454abd25748e5b5d3b28",
              "IPY_MODEL_29b5ba8bde024e239fff12e8180a5afe"
            ],
            "layout": "IPY_MODEL_9a5eef0ad8ec4f08b0b2bf8b19254233"
          }
        },
        "ce259f960f834820a14e38eff73e1be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c1b8d0fd0146029dcfab8cc824e664",
            "placeholder": "​",
            "style": "IPY_MODEL_492b3e337c774658b9c57e8a54300c68",
            "value": "vocab.txt: 100%"
          }
        },
        "be52db8d577e454abd25748e5b5d3b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a8607cd5994810b05da6506db7aacf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd45818ea4da43c1b7334f33891238b5",
            "value": 231508
          }
        },
        "29b5ba8bde024e239fff12e8180a5afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd230bbe1404e72abe9a8cfbc03efa6",
            "placeholder": "​",
            "style": "IPY_MODEL_a85cc2be909345f89c37aab95bbfb746",
            "value": " 232k/232k [00:00&lt;00:00, 2.86MB/s]"
          }
        },
        "9a5eef0ad8ec4f08b0b2bf8b19254233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c1b8d0fd0146029dcfab8cc824e664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492b3e337c774658b9c57e8a54300c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a8607cd5994810b05da6506db7aacf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd45818ea4da43c1b7334f33891238b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bd230bbe1404e72abe9a8cfbc03efa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85cc2be909345f89c37aab95bbfb746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "939a5c37325d4d70af059f79d3160ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c22065248ad64399a980cc6ea01c1a22",
              "IPY_MODEL_54326839415e49c4a24a0823142460c2",
              "IPY_MODEL_e70f641f53c640f1a54fb6687173ca8b"
            ],
            "layout": "IPY_MODEL_e9a0052949e64e628a148fe315612b22"
          }
        },
        "c22065248ad64399a980cc6ea01c1a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506ca83fd0a14ba08623cd4669b9982e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae89b55f3c0e438dbd33d21a64be81dd",
            "value": "tokenizer.json: 100%"
          }
        },
        "54326839415e49c4a24a0823142460c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c842ed6afb4843cfbf69adfb13b947b7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4976aa451e7942998c4e032b1a3f3d64",
            "value": 466062
          }
        },
        "e70f641f53c640f1a54fb6687173ca8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191ad8868d2c414287f53d095537cbda",
            "placeholder": "​",
            "style": "IPY_MODEL_baccfc87d97846d5b58c3b40cbbc55c4",
            "value": " 466k/466k [00:00&lt;00:00, 7.01MB/s]"
          }
        },
        "e9a0052949e64e628a148fe315612b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506ca83fd0a14ba08623cd4669b9982e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae89b55f3c0e438dbd33d21a64be81dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c842ed6afb4843cfbf69adfb13b947b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4976aa451e7942998c4e032b1a3f3d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "191ad8868d2c414287f53d095537cbda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baccfc87d97846d5b58c3b40cbbc55c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}